{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from functools import wraps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Designing the AB test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_power(n, power_1, power_2, confidence_level):\n",
    "    alpha = 1 - confidence_level\n",
    "    qu = stats.norm.ppf(1 - alpha/2)\n",
    "    diff = abs(power_2 - power_1)\n",
    "    bp = (power_1 + power_2)/2\n",
    "    v1 = power_1 * (1-power_1)\n",
    "    v2 = power_2 * (1-power_2)\n",
    "    bv = bp*(1-bp)\n",
    "    \n",
    "    temp_power_1 = stats.norm.cdf((n**0.5*diff - qu*(2*bv)**0.5) / (v1+v2)**0.5)\n",
    "    temp_power_2 = 1 - stats.norm.cdf((n**0.5*diff + qu*(2*bv)**0.5) / (v1+v2)**0.5)\n",
    "    \n",
    "    power = temp_power_1 + temp_power_2\n",
    "    \n",
    "    return power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_size(power, power_1, power_2, confidence_level, max_n):\n",
    "    n=1\n",
    "    while n <= max_n:\n",
    "        \n",
    "        temp_power = get_power(n, power_1, power_2, confidence_level)\n",
    "        \n",
    "        if temp_power >= power:\n",
    "            return n\n",
    "        else:\n",
    "            n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test with p1 & p2 value\n",
    "p1 = 0.1\n",
    "p2 = 0.12\n",
    "cl = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the impact of sample size increase on power\n",
    "n_param_one = get_power(n=1000, power_1=p1, power_2=p2, confidence_level=cl)\n",
    "n_param_two = get_power(n=2000, power_1=p1, power_2=p2, confidence_level=cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29808032538146\n",
      "0.524515256115834\n"
     ]
    }
   ],
   "source": [
    "print(n_param_one)\n",
    "print(n_param_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7596440001351992\n",
      "1.8857367092232278\n"
     ]
    }
   ],
   "source": [
    "n1 = 1000\n",
    "# Look at the impact of confidence level increase on power\n",
    "alpha_param_one = get_power(n=n1, power_1=p1, power_2=p2, confidence_level=0.8)\n",
    "alpha_param_two = get_power(n=n1, power_1=p1, power_2=p2, confidence_level=0.95)\n",
    "    \n",
    "# Compare the ratios\n",
    "print(n_param_two / n_param_one)\n",
    "print(alpha_param_one / alpha_param_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decrease of confidence level has more impact on the power than increasing the sample size "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining functions for Hypothesis testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis_testing_evaluation(func):\n",
    "    \"\"\"returns p_value & hypothesis testing results\"\"\"\n",
    "    \n",
    "    @wraps(func)\n",
    "    def wrapper_hypothesis(*args, **kwargs):\n",
    "        p_value = func(*args, **kwargs)\n",
    "        \n",
    "        if p_value >= 0.05:\n",
    "            print(\"Not significant test . Fail to reject the Null hypothesis\")\n",
    "        else:\n",
    "            print(\"Snignificative test. May reject the Null hypothesis\")\n",
    "        \n",
    "        return p_value\n",
    "    \n",
    "    return wrapper_hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@hypothesis_testing_evaluation\n",
    "def get_p_value(control_conversion_rate, test_conversion_rate, control_size, test_size):\n",
    "    lift = - abs(test_conversion_rate - control_conversion_rate)\n",
    "    \n",
    "    scale_control = control_conversion_rate * (1 - control_conversion_rate) * (1 / control_size)\n",
    "    scale_test = test_conversion_rate * (1 - test_conversion_rate) * (1 / test_size)\n",
    "    scale_val = (scale_control + scale_test)**0.5\n",
    "    \n",
    "    p_value = 2 * stats.norm.cdf(lift, loc=0, scale=scale_val)\n",
    "    \n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating p_value over "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snignificative test. May reject the Null hypothesis\n",
      "4.131297741047306e-06\n"
     ]
    }
   ],
   "source": [
    "p_value = get_p_value(control_conversion_rate=0.1, test_conversion_rate=0.17, control_size=1000, test_size=1000)\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not significant test . Fail to reject the Null hypothesis\n",
      "0.370901935824383\n"
     ]
    }
   ],
   "source": [
    "# Get the p-value\n",
    "p_value = get_p_value(control_conversion_rate=0.48, test_conversion_rate=0.5, control_size=1000, test_size=1000)\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         uid\n",
      "group       \n",
      "GRP A  23009\n",
      "GRP B  22874\n"
     ]
    }
   ],
   "source": [
    "ab_test_results =pd.read_csv('../data/ab_test_results.csv')\n",
    "# Compute and print the results\n",
    "results = ab_test_results.groupby('group').agg({'uid':pd.Series.nunique}) \n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significant Result. Reject null hypothesis.\n",
      "4.131297741047306e-06\n",
      "Not Significant. Fail to reject null hypothesis.\n",
      "0.370901935824383\n"
     ]
    }
   ],
   "source": [
    "def evaluate_null_hypo(func):\n",
    "    'Return the conclusion to Null Hypothesis'\n",
    "\n",
    "    @wraps(func)\n",
    "    def wrapper_hypo(*args, **kwargs):\n",
    "\n",
    "        p_value = func(*args, **kwargs)\n",
    "        # Check for statistical significance\n",
    "        if p_value >= 0.05:\n",
    "            print(\"Not Significant. Fail to reject null hypothesis.\")\n",
    "        else:\n",
    "            print(\"Significant Result. Reject null hypothesis.\")\n",
    "        return p_value\n",
    "\n",
    "    return wrapper_hypo\n",
    "\n",
    "\n",
    "@evaluate_null_hypo\n",
    "def get_pvalue(con_conv, test_conv, con_size, test_size):  \n",
    "    lift =  - abs(test_conv - con_conv)\n",
    "\n",
    "    scale_one = con_conv * (1 - con_conv) * (1 / con_size)\n",
    "    scale_two = test_conv * (1 - test_conv) * (1 / test_size)\n",
    "    scale_val = (scale_one + scale_two)**0.5\n",
    "\n",
    "    p_value = 2 * stats.norm.cdf(lift, loc = 0, scale = scale_val )\n",
    "\n",
    "    return p_value\n",
    "\n",
    "\n",
    "# Get the p-value\n",
    "p_value = get_pvalue(con_conv=0.1, test_conv=0.17, con_size=1000, test_size=1000)\n",
    "print(p_value)\n",
    "\n",
    "# Get the p-value\n",
    "p_value = get_pvalue(con_conv=0.48, test_conv=0.5, con_size=1000, test_size=1000)\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Conclusion part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
